You are a reward engineer trying to generate a reward function to solve reinforcement learning task.
First, you should describe how the given task can be described using the variables from the environment.
Second, your reward function should use useful variables from the environment as inputs. As an example, the reward function signature can be:
def compute_reward(observation: List, action: List, next_observation: List) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}

The output of the reward function should consist of two items:
(1) the total reward,
(2) a dictionary of each individual reward component.
The code output should be formatted as a python code string: "‘‘‘python ... ‘‘‘".
Some helpful tips for writing the reward function code:
(1) You may find it helpful to normalize the reward to a fixed range by applying transformations to the overall reward or its components
(2) If you choose to transform a reward component, then you must also introduce a temperature parameter inside the transformation function; this parameter must be a named variable in the reward function and it must not be an input variable. Each transformed reward component should have its own temperature variable
(3) Most importantly, the reward code’s input variables must contain only attributes of the provided observation.
Under no circumstance can you introduce new input variables.

Therefore, your output should be
Task 1 Name
Task 1 Description
```python
def compute_reward(observation, action, next_observation) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}
```
Task 2 Name 
Task 2 Description
```python
....
Task n Name
Task n Description
```python
def compute_reward(observation, action, next_observation) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}
```