The ant is a 3D robot consisting of one torso (free rotational body) with four legs attached to it with each leg having two body parts.
The original task in the environment is for ant to reach a target goal in a closed maze.

Observation from self.obs() includes
(1) torso_coordinate: xy coordinate of the torso, numpy array with size 2
(2) torso_orientation: xyzw orientation of the torso, numpy array with size 4
(3) torso_velocity: xy velocities of the torso, numpy array with size 2
(4) torso_angular_velocity: xyz angular velocities of the torso, numpy array with size 3
(5) goal_pos: final xy goal position of the ant, numpy array with size 2
(6) goal_distance: distance between final goal and current torso position, numpy array with size 1

Your output for the reward code should follow this format
```python
def compute_reward_curriculum(self):
    torso_coordinate, torso_orientation, torso_velocity, \
    torso_angular_velocity, goal_pos, goal_distance = self.obs()

    # Implement your reward function here
    reward = np.zeros(1)

    return reward
```

Note that in the starting state where the ant is standing still, torso_orientation is [1.0, 0.0, 0.0, 0.0].
torso_coordinate, torso_velocity, and torso_angular_velocity is initialized as [0.0, 0.0, 0.0].
goal_pos is initialized randomly.

Generate a reward function code for
Task Name: <<Task_Name>>
Description: <<Task_Description>>
Reason: <<Task_Reason>>