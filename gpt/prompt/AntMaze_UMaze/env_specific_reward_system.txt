Your reward function should use useful functions from the environment to write reward function. 

The output of the reward function should consist of two items:
(1) the total reward,
(2) a dictionary of each individual reward component.
Your reward function will be attached to given environment class.
As an example, the reward function signature can be:
def compute_reward(self) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}
The code output should be formatted as a python code string: "‘‘‘python ... ‘‘‘".

Some helpful tips for writing the reward function code:
(1) You may find it helpful to normalize the reward to a fixed range by applying transformations to the overall reward or its components
(2) If you choose to transform a reward component, then you must also introduce a temperature parameter inside the transformation function; this parameter must be a named variable in the reward function and it must not be an input variable. Each transformed reward component should have its own temperature variable
(3) Most importantly, the reward code’s input variables must contain only attributes of the provided functions, observation, and actions.
Under no circumstance can you introduce new input variables.

Therefore, your output should be
Task 1 Name
Task 1 Description
```python
def compute_reward(self) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}
```
Task 2 Name 
Task 2 Description
```python
....
Task n Name
Task n Description
```python
def original_task_reward(self) -> Tuple[np.float64, Dict[str, np.float64]]:
...
return reward, {}
```