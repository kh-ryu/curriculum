This environment is Fetch-Pick and Place environment
The original task in the environment is for a manipulator to move a block to a target position on top of a table or in mid-air. 
The robot is a 7-DoF Fetch Mobile Manipulator with a two-fingered parallel gripper.  
The gripper can be opened or closed in order to perform the grasping operation of pick and place.

The variables you can use to describe the reward function includes
(1) end_effector_position: xyz position of end effector
(2) block_position: xyz position a block which robot should move
(3) gripper_distance: Joint distance of the right and left gripper finger
(4) block_relative_linear_velocity: Linear velocity of block - Linear velocity of end effector
(5) end_effector_linear_velocity: Linear velocity of end effector
(6) goal_position: Desired goal position in xyz coordinate 

Environment code is
```python
def compute_reward_curriculum(self):
    end_effector_position, block_position, gripper_distance, \
    block_relative_linear_velocity, end_effector_linear_velocity, \
    goal_position = self.obs()

    # Implement your reward function here
    reward = np.zeros(1)

    return reward
```

Since the block is placed on a table, it has a fixed height of z = 0.42 when it is initialized.
Also, goal position is in a range of height [0.42, 0.87], while its xy position is initialized randomly.

Generate a reward function code for
Task Name: <<Task_Name>>
Description: <<Task_Description>>
Reason: <<Task_Reason>>