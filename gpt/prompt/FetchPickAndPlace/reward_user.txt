This environment is Fetch-Pick and Place environment
The original task in the environment is for a manipulator to move a block to a target position on top of a table or in mid-air. 
The robot is a 7-DoF Fetch Mobile Manipulator with a two-fingered parallel gripper.  
The gripper can be opened or closed in order to perform the grasping operation of pick and place.

The variables you can use to describe the reward function includes
(1) end_effector_position: xyz position of end effector
(2) block_position: xyz position a block which robot should move
(3) gripper_distance: Joint distance of the right and left gripper finger
(4) block_linear_velocity: Linear velocity of block
(5) end_effector_linear_velocity: Linear velocity of end effector
(6) goal_position: Desired goal position in xyz coordinate 

Environment code is
```python
def compute_reward_curriculum(self):
    end_effector_position, block_position, gripper_distance, \
    block_linear_velocity, end_effector_linear_velocity, \
    goal_position = self.obs()

    # Implement your reward function here
    reward = np.zeros(1)

    return reward
```

Note that since the block is placed on a table, it has a fixed height of z = 2.1 when it is initialized.
Note that goal position can be mid-air over the table
Note that xy coordinate goal position is initialized randomly and you cannot change it. 

Generate a reward function code for
Task Name: <<Task_Name>>
Description: <<Task_Description>>
Reason: <<Task_Reason>>